#!/usr/bin/env python3
"""
ä¸“å®¶è®­ç»ƒç³»ç»Ÿæµ‹è¯•è„šæœ¬
éªŒè¯ç³»ç»Ÿå„ä¸ªç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import json
import logging
import sys
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_file_structure():
    """æµ‹è¯•æ–‡ä»¶ç»“æ„"""
    logger.info("=== æµ‹è¯•æ–‡ä»¶ç»“æ„ ===")
    
    required_files = [
        "enhanced_rl_training_with_expert.py",
        "simple_expert_training_demo.py", 
        "run_expert_training.py",
        "configs/expert_training_config.json",
        "docs/EXPERT_TRAINING_GUIDE.md"
    ]
    
    missing_files = []
    for file_path in required_files:
        full_path = project_root / file_path
        if not full_path.exists():
            missing_files.append(file_path)
        else:
            logger.info(f"âœ“ {file_path}")
    
    if missing_files:
        logger.error(f"ç¼ºå°‘æ–‡ä»¶: {missing_files}")
        return False
    
    logger.info("æ–‡ä»¶ç»“æ„æµ‹è¯•é€šè¿‡")
    return True

def test_design_data():
    """æµ‹è¯•è®¾è®¡æ•°æ®"""
    logger.info("=== æµ‹è¯•è®¾è®¡æ•°æ® ===")
    
    design_dir = project_root / "data/designs/ispd_2015_contest_benchmark/mgc_des_perf_1"
    
    if not design_dir.exists():
        logger.error(f"è®¾è®¡ç›®å½•ä¸å­˜åœ¨: {design_dir}")
        return False
    
    required_design_files = [
        "floorplan.def",
        "mgc_des_perf_1_place.def", 
        "design.v",
        "cells.lef",
        "tech.lef"
    ]
    
    missing_files = []
    for file_name in required_design_files:
        file_path = design_dir / file_name
        if not file_path.exists():
            missing_files.append(file_name)
        else:
            file_size = file_path.stat().st_size
            logger.info(f"âœ“ {file_name} ({file_size / 1024 / 1024:.1f} MB)")
    
    if missing_files:
        logger.error(f"ç¼ºå°‘è®¾è®¡æ–‡ä»¶: {missing_files}")
        return False
    
    logger.info("è®¾è®¡æ•°æ®æµ‹è¯•é€šè¿‡")
    return True

def test_config_loading():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    logger.info("=== æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½ ===")
    
    config_path = project_root / "configs/expert_training_config.json"
    
    try:
        with open(config_path, 'r') as f:
            config = json.load(f)
        
        # æ£€æŸ¥é…ç½®ç»“æ„
        required_sections = ['expert_training', 'simple_demo']
        for section in required_sections:
            if section not in config:
                logger.error(f"é…ç½®ç¼ºå°‘éƒ¨åˆ†: {section}")
                return False
        
        logger.info("âœ“ é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        logger.info(f"  - ä¸“å®¶è®­ç»ƒé…ç½®: {len(config['expert_training'])} ä¸ªéƒ¨åˆ†")
        logger.info(f"  - ç®€åŒ–æ¼”ç¤ºé…ç½®: {len(config['simple_demo'])} ä¸ªéƒ¨åˆ†")
        
        return True
        
    except Exception as e:
        logger.error(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return False

def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    logger.info("=== æµ‹è¯•æ¨¡å—å¯¼å…¥ ===")
    
    try:
        # æµ‹è¯•åŸºç¡€æ¨¡å—å¯¼å…¥
        import torch
        import numpy as np
        logger.info("âœ“ åŸºç¡€æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•é¡¹ç›®æ¨¡å—å¯¼å…¥
        from modules.parsers.def_parser import parse_def
        from modules.parsers.design_parser import parse_verilog
        logger.info("âœ“ é¡¹ç›®æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•ä¸“å®¶è®­ç»ƒæ¨¡å—å¯¼å…¥
        from enhanced_rl_training_with_expert import ExpertDataManager, EnhancedDesignEnvironment
        logger.info("âœ“ ä¸“å®¶è®­ç»ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except ImportError as e:
        logger.error(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.error(f"å¯¼å…¥æµ‹è¯•å‡ºé”™: {e}")
        return False

def test_expert_data_parsing():
    """æµ‹è¯•ä¸“å®¶æ•°æ®è§£æ"""
    logger.info("=== æµ‹è¯•ä¸“å®¶æ•°æ®è§£æ ===")
    
    try:
        design_dir = project_root / "data/designs/ispd_2015_contest_benchmark/mgc_des_perf_1"
        
        # æµ‹è¯•DEFè§£æ
        floorplan_def = design_dir / "floorplan.def"
        expert_def = design_dir / "mgc_des_perf_1_place.def"
        
        from modules.parsers.def_parser import parse_def
        from modules.parsers.design_parser import parse_verilog
        
        floorplan_metrics = parse_def(str(floorplan_def))
        expert_metrics = parse_def(str(expert_def))
        
        logger.info(f"âœ“ Floorplanè§£ææˆåŠŸ: {floorplan_metrics.get('num_components', 0)} ä¸ªç»„ä»¶")
        logger.info(f"âœ“ Expertè§£ææˆåŠŸ: {expert_metrics.get('num_components', 0)} ä¸ªç»„ä»¶")
        
        # æ¯”è¾ƒä¸¤ä¸ªDEFæ–‡ä»¶
        floorplan_area = floorplan_metrics.get('die_area_microns', (0, 0))
        expert_area = expert_metrics.get('die_area_microns', (0, 0))
        
        logger.info(f"  - Floorplané¢ç§¯: {floorplan_area[0]} x {floorplan_area[1]}")
        logger.info(f"  - Experté¢ç§¯: {expert_area[0]} x {expert_area[1]}")
        
        return True
        
    except Exception as e:
        logger.error(f"ä¸“å®¶æ•°æ®è§£æå¤±è´¥: {e}")
        return False

def test_network_creation():
    """æµ‹è¯•ç½‘ç»œåˆ›å»º"""
    logger.info("=== æµ‹è¯•ç½‘ç»œåˆ›å»º ===")
    
    try:
        import torch
        from enhanced_rl_training_with_expert import ExpertGuidedActorCritic
        
        # åˆ›å»ºç½‘ç»œ
        state_dim = 8
        action_dim = 13
        network = ExpertGuidedActorCritic(state_dim, action_dim)
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        dummy_state = torch.randn(1, state_dim)
        action_probs, state_value, expert_probs = network(dummy_state)
        
        logger.info(f"âœ“ ç½‘ç»œåˆ›å»ºæˆåŠŸ")
        logger.info(f"  - åŠ¨ä½œæ¦‚ç‡å½¢çŠ¶: {action_probs.shape}")
        logger.info(f"  - çŠ¶æ€ä»·å€¼å½¢çŠ¶: {state_value.shape}")
        logger.info(f"  - ä¸“å®¶æ¦‚ç‡å½¢çŠ¶: {expert_probs.shape}")
        
        # æ£€æŸ¥è¾“å‡ºåˆç†æ€§
        assert action_probs.sum().item() > 0.99, "åŠ¨ä½œæ¦‚ç‡å’Œä¸ä¸º1"
        assert expert_probs.sum().item() > 0.99, "ä¸“å®¶æ¦‚ç‡å’Œä¸ä¸º1"
        
        return True
        
    except Exception as e:
        logger.error(f"ç½‘ç»œåˆ›å»ºå¤±è´¥: {e}")
        return False

def test_simple_demo():
    """æµ‹è¯•ç®€åŒ–æ¼”ç¤º"""
    logger.info("=== æµ‹è¯•ç®€åŒ–æ¼”ç¤º ===")
    
    try:
        from simple_expert_training_demo import SimpleExpertDataManager, SimpleExpertEnvironment
        
        design_dir = project_root / "data/designs/ispd_2015_contest_benchmark/mgc_des_perf_1"
        
        # åˆ›å»ºä¸“å®¶æ•°æ®ç®¡ç†å™¨
        expert_data = SimpleExpertDataManager(str(design_dir))
        logger.info("âœ“ ä¸“å®¶æ•°æ®ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºç¯å¢ƒ
        env = SimpleExpertEnvironment(str(design_dir), expert_data)
        logger.info("âœ“ ç®€åŒ–ç¯å¢ƒåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•çŠ¶æ€è·å–
        state = env.get_state()
        logger.info(f"âœ“ çŠ¶æ€è·å–æˆåŠŸï¼Œç»´åº¦: {state.shape}")
        
        # æµ‹è¯•åŠ¨ä½œæ‰§è¡Œ
        action_k = 6
        next_state, reward, done, info = env.step(action_k)
        logger.info(f"âœ“ åŠ¨ä½œæ‰§è¡ŒæˆåŠŸï¼Œå¥–åŠ±: {reward:.3f}")
        
        return True
        
    except Exception as e:
        logger.error(f"ç®€åŒ–æ¼”ç¤ºæµ‹è¯•å¤±è´¥: {e}")
        return False

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("=================================================")
    logger.info("=== ä¸“å®¶è®­ç»ƒç³»ç»Ÿæµ‹è¯•å¼€å§‹ ===")
    logger.info("=================================================")
    
    tests = [
        ("æ–‡ä»¶ç»“æ„", test_file_structure),
        ("è®¾è®¡æ•°æ®", test_design_data),
        ("é…ç½®åŠ è½½", test_config_loading),
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("ä¸“å®¶æ•°æ®è§£æ", test_expert_data_parsing),
        ("ç½‘ç»œåˆ›å»º", test_network_creation),
        ("ç®€åŒ–æ¼”ç¤º", test_simple_demo)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
                logger.info(f"âœ“ {test_name} æµ‹è¯•é€šè¿‡")
            else:
                logger.error(f"âœ— {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            logger.error(f"âœ— {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
    
    logger.info("=================================================")
    logger.info(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
        logger.info("\nä¸‹ä¸€æ­¥:")
        logger.info("1. è¿è¡Œç®€åŒ–æ¼”ç¤º: python run_expert_training.py --mode demo")
        logger.info("2. è¿è¡Œå®Œæ•´è®­ç»ƒ: python run_expert_training.py --mode full")
        logger.info("3. æŸ¥çœ‹ä½¿ç”¨æŒ‡å—: docs/EXPERT_TRAINING_GUIDE.md")
    else:
        logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®ã€‚")
    
    return passed == total

if __name__ == '__main__':
    success = run_all_tests()
    sys.exit(0 if success else 1) 