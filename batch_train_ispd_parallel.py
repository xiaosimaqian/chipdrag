#!/usr/bin/env python3
"""
å¹¶è¡Œå¤„ç†çš„ISPD 2015æ‰¹é‡è®­ç»ƒè„šæœ¬
æ”¯æŒè·³è¿‡å¤§å‹è®¾è®¡ï¼Œè®­ç»ƒ/æµ‹è¯•é›†åˆ†å‰²ï¼Œå¹¶è¡Œå¤„ç†
"""

import os
import sys
import time
import json
import logging
from pathlib import Path
from datetime import datetime
from multiprocessing import Pool, cpu_count
from concurrent.futures import ProcessPoolExecutor, as_completed

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from modules.rl_training.real_openroad_interface_fixed import RealOpenROADInterface

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('parallel_training.log'),
        logging.StreamHandler()
    ]
)

# è·³è¿‡å¤§å‹è®¾è®¡ï¼ˆå¤„ç†æ—¶é—´è¿‡é•¿ï¼‰
SKIP_LARGE_DESIGNS = {
    'mgc_superblue16_a', 'mgc_superblue11_a', 'mgc_des_perf_a'
}

def get_design_size(design_dir):
    """ä¼°ç®—è®¾è®¡è§„æ¨¡"""
    try:
        verilog_file = Path(design_dir) / 'design.v'
        with open(verilog_file, 'r') as f:
            content = f.read()
            # ç»Ÿè®¡å®ä¾‹æ•°é‡
            instances = len([line for line in content.split('\n') if 'module' in line and 'endmodule' not in line])
            return instances
    except:
        return 0

def find_ispd_designs():
    """æŸ¥æ‰¾æ‰€æœ‰ISPD 2015è®¾è®¡ï¼ŒæŒ‰è§„æ¨¡åˆ†ç±»"""
    designs_dir = Path('data/designs/ispd_2015_contest_benchmark')
    small_designs = []
    large_designs = []
    
    if not designs_dir.exists():
        logging.error(f"è®¾è®¡ç›®å½•ä¸å­˜åœ¨: {designs_dir}")
        return small_designs, large_designs
    
    for design_dir in designs_dir.iterdir():
        if not design_dir.is_dir():
            continue
            
        design_name = design_dir.name
        if design_name in SKIP_LARGE_DESIGNS:
            logging.info(f"è·³è¿‡å¤§å‹è®¾è®¡: {design_name}")
            continue
            
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        verilog_file = design_dir / 'design.v'
        floorplan_def = design_dir / 'floorplan.def'
        tech_lef = design_dir / 'tech.lef'
        cells_lef = design_dir / 'cells.lef'
        
        if all(f.exists() for f in [verilog_file, floorplan_def, tech_lef, cells_lef]):
            size = get_design_size(design_dir)
            if size > 100000:  # å¤§å‹è®¾è®¡
                large_designs.append(design_name)
                logging.info(f"æ‰¾åˆ°å¤§å‹è®¾è®¡: {design_name} ({size}å®ä¾‹)")
            else:
                small_designs.append(design_name)
                logging.info(f"æ‰¾åˆ°ä¸­å°å‹è®¾è®¡: {design_name} ({size}å®ä¾‹)")
    
    return small_designs, large_designs

def split_train_test(designs):
    """åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†"""
    if len(designs) <= 1:
        return designs, []
    
    # ä¿ç•™1ä¸ªè®¾è®¡ä½œä¸ºæµ‹è¯•é›†
    test_design = designs[-1]  # é€‰æ‹©æœ€åä¸€ä¸ªä½œä¸ºæµ‹è¯•é›†
    train_designs = designs[:-1]  # å…¶ä½™ä½œä¸ºè®­ç»ƒé›†
    
    return train_designs, [test_design]

def train_single_design(design_name):
    """è®­ç»ƒå•ä¸ªè®¾è®¡"""
    try:
        design_dir = f"data/designs/ispd_2015_contest_benchmark/{design_name}"
        
        # åˆ›å»ºOpenROADæ¥å£
        interface = RealOpenROADInterface(design_dir)
        
        # æ ¹æ®è®¾è®¡è§„æ¨¡è®¾ç½®è¶…æ—¶
        size = get_design_size(design_dir)
        if size > 50000:
            timeout = 1200  # 20åˆ†é’Ÿ
        else:
            timeout = 600   # 10åˆ†é’Ÿ
        
        # è¿è¡Œè¿­ä»£å¸ƒå±€è®­ç»ƒ
        logging.info(f"å¼€å§‹è®­ç»ƒè®¾è®¡: {design_name} (è¶…æ—¶: {timeout}ç§’)")
        result = interface.run_iterative_placement(num_iterations=10, timeout=timeout)
        
        if result['success']:
            logging.info(f"âœ… è®¾è®¡ {design_name} è®­ç»ƒæˆåŠŸ")
            return {
                'design': design_name,
                'success': True,
                'execution_time': result['execution_time'],
                'iterations': result['iterations'],
                'final_hpwl': result.get('final_hpwl', None)
            }
        else:
            logging.error(f"âŒ è®¾è®¡ {design_name} è®­ç»ƒå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return {
                'design': design_name,
                'success': False,
                'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
            }
            
    except Exception as e:
        logging.error(f"âŒ è®¾è®¡ {design_name} è®­ç»ƒå¼‚å¸¸: {str(e)}")
        return {
            'design': design_name,
            'success': False,
            'error': str(e)
        }

def main():
    """ä¸»å‡½æ•°"""
    logging.info("å¼€å§‹å¹¶è¡Œæ‰¹é‡è®­ç»ƒï¼ˆè®­ç»ƒ/æµ‹è¯•é›†åˆ†å‰²ï¼‰")
    
    # æŸ¥æ‰¾æ‰€æœ‰è®¾è®¡
    small_designs, large_designs = find_ispd_designs()
    
    if not small_designs:
        logging.error("æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ä¸­å°å‹è®¾è®¡")
        return
    
    # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    train_designs, test_designs = split_train_test(small_designs)
    
    logging.info(f"ä¸­å°å‹è®¾è®¡æ€»æ•°: {len(small_designs)}")
    logging.info(f"è®­ç»ƒé›†: {len(train_designs)} ä¸ªè®¾è®¡ - {train_designs}")
    logging.info(f"æµ‹è¯•é›†: {len(test_designs)} ä¸ªè®¾è®¡ - {test_designs}")
    logging.info(f"è·³è¿‡å¤§å‹è®¾è®¡: {len(large_designs)} ä¸ª")
    
    # åˆ›å»ºç»“æœç›®å½•
    results_dir = Path('results/parallel_training')
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æ•°æ®é›†åˆ†å‰²ä¿¡æ¯
    dataset_info = {
        'train_designs': train_designs,
        'test_designs': test_designs,
        'skipped_large_designs': list(large_designs),
        'total_small_designs': len(small_designs),
        'total_large_designs': len(large_designs)
    }
    
    with open(results_dir / 'dataset_split.json', 'w') as f:
        json.dump(dataset_info, f, indent=2)
    
    # å¤„ç†è®­ç»ƒé›†ï¼ˆå¹¶è¡Œï¼‰
    results = []
    start_time = time.time()
    
    if train_designs:
        logging.info(f"å¼€å§‹å¹¶è¡Œå¤„ç†è®­ç»ƒé›†: {len(train_designs)} ä¸ªè®¾è®¡")
        
        # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†
        max_workers = min(cpu_count(), 4)  # æœ€å¤š4ä¸ªè¿›ç¨‹
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_design = {executor.submit(train_single_design, design): design 
                              for design in train_designs}
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_design):
                design = future_to_design[future]
                try:
                    result = future.result()
                    result['dataset'] = 'train'  # æ ‡è®°ä¸ºè®­ç»ƒé›†
                    results.append(result)
                    logging.info(f"å®Œæˆè®­ç»ƒè®¾è®¡: {design}")
                except Exception as e:
                    logging.error(f"è®­ç»ƒè®¾è®¡ {design} å¤„ç†å¼‚å¸¸: {e}")
                    results.append({
                        'design': design,
                        'dataset': 'train',
                        'success': False,
                        'error': str(e)
                    })
    
    total_time = time.time() - start_time
    
    # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
    successful = sum(1 for r in results if r['success'])
    failed = len(results) - successful
    
    report = f"""
# å¹¶è¡Œæ‰¹é‡è®­ç»ƒæŠ¥å‘Šï¼ˆè®­ç»ƒ/æµ‹è¯•é›†åˆ†å‰²ï¼‰

## è®­ç»ƒæ¦‚è§ˆ
- å¼€å§‹æ—¶é—´: {datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S')}
- ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- æ€»è€—æ—¶: {total_time:.2f} ç§’

## æ•°æ®é›†åˆ†å‰²
- ä¸­å°å‹è®¾è®¡æ€»æ•°: {len(small_designs)}
- è®­ç»ƒé›†: {len(train_designs)} ä¸ªè®¾è®¡
- æµ‹è¯•é›†: {len(test_designs)} ä¸ªè®¾è®¡
- è·³è¿‡å¤§å‹è®¾è®¡: {len(large_designs)} ä¸ª

## è®­ç»ƒç»“æœ
- è®­ç»ƒè®¾è®¡æ€»æ•°: {len(train_designs)}
- æˆåŠŸ: {successful}
- å¤±è´¥: {failed}
- æˆåŠŸç‡: {successful/len(train_designs)*100:.1f}% (å¦‚æœè®­ç»ƒé›†ä¸ä¸ºç©º)

## å¤„ç†ç­–ç•¥
- è·³è¿‡å¤§å‹è®¾è®¡: {', '.join(SKIP_LARGE_DESIGNS)}
- è®­ç»ƒé›†: å¹¶è¡Œå¤„ç†
- æµ‹è¯•é›†: ä¿ç•™ç”¨äºåç»­å®éªŒ
- æœ€å¤§å¹¶è¡Œæ•°: {min(cpu_count(), 4)}

## è®­ç»ƒé›†è¯¦ç»†ç»“æœ
"""
    
    for result in results:
        if result['success']:
            report += f"- âœ… {result['design']}: è€—æ—¶ {result['execution_time']:.1f}ç§’\n"
        else:
            report += f"- âŒ {result['design']}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}\n"
    
    if test_designs:
        report += f"\n## æµ‹è¯•é›†ï¼ˆä¿ç•™ç”¨äºåç»­å®éªŒï¼‰\n"
        for design in test_designs:
            report += f"- ğŸ”¬ {design}\n"
    
    # ä¿å­˜æŠ¥å‘Š
    with open(results_dir / 'parallel_training_report.md', 'w') as f:
        f.write(report)
    
    # ä¿å­˜ç»“æœ
    with open(results_dir / 'parallel_training_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    logging.info(f"å¹¶è¡Œæ‰¹é‡è®­ç»ƒå®Œæˆï¼")
    logging.info(f"è®­ç»ƒé›†æˆåŠŸ: {successful}/{len(train_designs)}")
    logging.info(f"æµ‹è¯•é›†ä¿ç•™: {len(test_designs)} ä¸ªè®¾è®¡")
    logging.info(f"ç»“æœå·²ä¿å­˜åˆ°: {results_dir}")

if __name__ == '__main__':
    main() 